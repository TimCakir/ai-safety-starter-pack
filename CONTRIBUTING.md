# Contributing to AI Safety Starter Pack

Thank you for your interest in improving the AI Safety Starter Pack! This project helps organizations implement AI governance safely and compliantly.

## How to Contribute

### üêõ Report Issues

Found an error, outdated information, or compliance gap? Please open an issue:

1. **Check existing issues** first to avoid duplicates
2. **Use a clear title**: "GDPR: Article 28 reference incorrect in DPA Guide"
3. **Provide context**:
   - Which guide/section?
   - What's wrong?
   - What should it say?
   - Source/citation if applicable

**Priority areas for issue reports**:
- Regulatory updates (GDPR, EU AI Act, CCPA changes)
- Tool policy changes (OpenAI, Anthropic, Google, Microsoft)
- Real-world incidents (new breaches, fines, case studies)
- Legal inaccuracies (requires citation)

### üí° Suggest Improvements

Have an idea to make the guides more useful? Open a feature request:

**Good suggestions**:
- "Add section on AI coding tools (GitHub Copilot, Cursor) to Safe AI Stack"
- "Include HIPAA BAA checklist in DPA Guide"
- "Add financial services use case to Governance Blueprint"

**What we're NOT looking for**:
- Generic security advice unrelated to AI governance
- Promotional content for specific vendors
- Theoretical frameworks without practical implementation

### üìù Submit Updates

Want to contribute directly? Here's how:

#### Small Fixes (typos, formatting, broken links)
1. Fork the repository
2. Make your changes
3. Submit a pull request with clear description
4. Maintainer will review within 5-7 days

#### Substantial Changes (new sections, policy updates, regulatory changes)
1. **Open an issue first** to discuss the change
2. Wait for maintainer approval
3. Fork the repository
4. Create a branch: `git checkout -b feature/your-feature-name`
5. Make your changes
6. Add citations/sources for factual claims
7. Update CHANGELOG.md
8. Submit pull request

**Pull Request Checklist**:
- [ ] Changes are factually accurate (cite sources)
- [ ] Maintains Tim Cakir's voice and methodology
- [ ] Follows existing formatting and structure
- [ ] No promotional content or vendor bias
- [ ] Tested/reviewed by legal counsel if applicable
- [ ] CHANGELOG.md updated
- [ ] Clear description of what changed and why

### üìö Share Real-World Examples

The most valuable contributions are **real-world case studies**:

- AI governance implementations that worked (or failed)
- Regulatory enforcement actions
- Data breaches involving AI tools
- Audit findings from your organization (anonymized)

**How to share**:
1. Open an issue with "Case Study:" prefix
2. Include: What happened, impact, lessons learned, sources
3. Anonymize company names if necessary
4. Provide public sources where possible

### üîí Responsible Disclosure

If you discover a **security vulnerability** in the guidance or templates:

**DO NOT open a public issue.**

Instead:
1. Email: [security contact email - Tim should provide]
2. Include: Description, potential impact, suggested fix
3. Allow 90 days for response before public disclosure

## Contribution Guidelines

### Code of Conduct

- **Be respectful**: Constructive criticism only
- **Be factual**: Cite sources for claims
- **Be practical**: Focus on actionable guidance
- **No self-promotion**: No vendor pitches or affiliate links

### Style Guide

**Tone**: Direct, practical, evidence-based (like Tim Cakir's voice)
- ‚úÖ "Based on 500+ audits, 81% of organizations lack visibility into AI tool usage"
- ‚ùå "Many organizations struggle with AI governance challenges"

**Formatting**:
- Use markdown headings (H1, H2, H3) consistently
- Include tables for comparisons
- Add checklists for actionable items
- Cite sources with links
- Use bold for emphasis, not italics

**Citations**:
- Regulatory sources: Link to official documents (EUR-Lex, Federal Register)
- Statistics: Include source, date, sample size
- Case studies: Link to public reporting (news, regulatory filings)
- Tools/vendors: Link to official documentation only

### What Gets Accepted

**High Priority**:
- ‚úÖ Regulatory updates (EU AI Act, GDPR enforcement)
- ‚úÖ Tool policy changes (OpenAI DPA updates, Microsoft Copilot features)
- ‚úÖ Real-world incidents (new fines, breaches)
- ‚úÖ Factual corrections with citations

**Medium Priority**:
- ‚ö†Ô∏è New sections (if they fit the scope)
- ‚ö†Ô∏è Additional use cases
- ‚ö†Ô∏è Industry-specific guidance (healthcare, finance)

**Low Priority / Usually Rejected**:
- ‚ùå Theoretical frameworks without practical steps
- ‚ùå Vendor-specific implementation guides
- ‚ùå General cybersecurity advice (not AI-specific)
- ‚ùå Opinion pieces without evidence

## Review Process

1. **Submission**: You submit issue or PR
2. **Initial Review** (5-7 days): Maintainer assesses relevance
3. **Discussion**: Clarifying questions, scope refinement
4. **Legal Review** (if needed): For regulatory/compliance changes
5. **Approval or Rejection**: With explanation
6. **Merge**: Changes incorporated, CHANGELOG updated

**Timeline expectations**:
- Typo fixes: 1-3 days
- Small updates: 5-7 days
- Substantial changes: 2-4 weeks (includes legal review)
- Regulatory changes: Prioritized for next release

## Recognition

Contributors will be acknowledged in:
- CHANGELOG.md (for each release)
- README.md (major contributors)
- Commit history (all contributions)

**Significant contributions** (50+ lines, new sections, regulatory updates) may include:
- LinkedIn shoutout from Tim Cakir
- Co-author attribution for specific guides

## Versioning

This project uses semantic versioning:
- **Major** (2.0.0): Complete restructure or regulatory paradigm shift
- **Minor** (1.1.0): New guides, substantial sections, tool additions
- **Patch** (1.0.1): Corrections, small updates, regulatory clarifications

Current version: **1.0** (October 2025)

## Questions?

Not sure if your contribution fits? Open an issue with "Question:" prefix or contact:

- **GitHub Issues**: https://github.com/TimCakir/ai-safety-starter-pack/issues
- **LinkedIn**: https://linkedin.com/in/timcakir
- **Website**: https://aioperator.com

---

## License

By contributing, you agree that your contributions will be licensed under the same Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License as the project.

You retain copyright to your contributions but grant AI Operator a perpetual license to use them.

---

**Thank you for helping make AI governance more accessible!** üôè
